%% Pregunta 2: Tarea 3 (Econometría I)

clear all
clc

rng(1)               % Semilla. 

%% Pregunta 1: W_i no observable.

% Si W_i no es observable, tampoco entrará dentro de nuestro instrumento.
% De esta forma, la primera y segunda etapa serán respectivamente:

for a1 = [0.1, 0.5, 1, 5, 10]

b0 = 1;
b1 = 2;
b2 = 5;

a0 = -4;
a2 = 3; 

N = 1000;

e_i = randn(N,1);
u_i = randn(N,1);
W_i = normrnd(2, 1, N, 1);
v_i = rand(N, 1); 

Z_i = zeros(N,1); 
for i = 1:N
    if v_i(i) < 0.8                       
       Z_i(i) = 1;  
    else             
       Z_i(i) = 0;
    end
end

X_i = a0 + a1*Z_i + a2*W_i + u_i;    % Primera etapa.
Y = b0 + b1*X_i + b2*W_i + e_i;    % Segunda etapa.

X = [ones(N,1), X_i];

beta_gorro = inv(X'*X)*X'*Y;

u_gorro = Y - X*beta_gorro;

K = length(beta_gorro);

% Errores estándares.

s = (u_gorro'*u_gorro)/(N-K);    % Varianza estimada del error.
se = sqrt(s*diag(inv(X'*X)));    % Error estándar homocedástico.
se_r = sqrt(diag(inv(X'*X)*(X'*(diag(u_gorro.^2))*(N/(N-K))*X)*inv(X'*X))); % Error estándar robusto.

Pregunta1 = table(beta_gorro, se, se_r, ...
    'VariableNames', {'Coeficiente', 'SE', 'SE Robusto'});
disp(['Para un alpha_1 = ', num2str(a1), ', los coeficientes y errores estándares son:']);
disp(Pregunta1);
end

%% Pregunta 2: Distribución asintótica por Montecarlo.

% Se repite el mismo procedimiento de la pregunta a), pero considerando las
% B = 1000 simulaciones para beta.

for a1 = [0.1, 0.5, 1, 5, 10]

B = 1000;         % Número de simulaciones. 
bm = NaN(2,B);    % Vector de coeficientes simulados por Montecarlo.

for i = 1:B
    X_i = a0 + a1*Z_i + a2*W_i + u_i;    % Primera etapa.
    Y = b0 + b1*X_i + b2*W_i + e_i;    % Segunda etapa.

    X = [ones(N,1), X_i];   % Primera etapa omitiendo W_i.
    
    m = randi(N,N,1);      % Vector de m pares aleatorios intependientes de tamaño n. 
    bm(:,i) = (X(m,:)'*X(m,:))\(X(m,:)'*Y(m)) ;
end
bm = sort(bm,2);

% Sesgo.
sesgo = mean(bm(2,:))- b1;
disp(['Para un alpha_1 = ', num2str(a1), ', el sesgo de nuestro estimador de MCO será:']);
    disp(sesgo);

% Calcular la densidad estimada
hold on;
[f,xi] = ksdensity(bm(2, :));
plot(xi,f,'LineWidth',2);
hold off;
end

xlabel('Valor');
ylabel('Densidad');
title('Curva de densidad estimada $\hat{\beta}_{1}$', 'Interpreter','latex');
legend('$\alpha_1 = 0.1$', '$\alpha_1 = 0.5$','$\alpha_1 = 1$', ...
    '$\alpha_1 = 5$', '$\alpha_1 = 10$','Interpreter','latex');
filename = ['densidad_alpha.png'];
    saveas(gcf, filename);
% El sesgo se reduce con un alpha_1 más grande. 
% Según la el manual de ivregress en stata: Both theoretical and Monte Carlo exercises indicate 
% that the LIML estimator may yield less bias and confidence intervals with better coverage rates 
% than the 2SLS estimator. See Poi (2006) and Stock, Wright, and Yogo (2002) (and the papers cited 
% therein) for Monte Carlo evidence

%% Pregunta 3: Estimación por MC2E.
clear all   % Se hace clear all. De lo contrario los resultados se traslapan.

rng(1)               % Semilla.

for a1 = [0.1, 0.5, 1, 5, 10]


N = 1000;

b0 = 1;
b1 = 2;
b2 = 5;

a0 = -4;
a2 = 3; 

e_i = randn(N,1);
u_i = randn(N,1);
W_i = normrnd(2, 1, N, 1);
v_i = rand(N, 1); 

Z_i = zeros(N,1); 
for i = 1:N
    if v_i(i) < 0.8                       
       Z_i(i) = 1;  
    else             
       Z_i(i) = 0;
    end
end

X_i = a0 + a1*Z_i + a2*W_i + u_i; 
Y = b0 + b1*X_i + b2*W_i + e_i;

% Primera etapa.

Z = [ones(N,1), Z_i];          % Omitimos W_i.
zeta_gorro = inv(Z'*Z)*Z'*X_i;  

u_gorro = X_i - Z*zeta_gorro;

% Segunda etapa.

X_hat = Z*zeta_gorro + u_gorro;

X = [ones(N,1), X_hat];         % Omitimos W_i.
beta_gorro = inv(X'*X)*X'*Y;

e_gorro = Y - X*beta_gorro;

% Errores estándares - Segunda Etapa.

K = length(beta_gorro);

s = (e_gorro'*e_gorro)/(N-K);    % Varianza estimada del error.
se = sqrt(s*diag(inv(X'*X)));    % Error estándar homocedástico.
se_r = sqrt(diag(inv(X'*X)*(X'*(diag(e_gorro.^2))*(N/(N-K))*X)*inv(X'*X))); % Error estándar robusto.

% Errores estándar - Primera Etapa.

K = length(zeta_gorro);

s1 = (u_gorro'*u_gorro)/(N-K);    % Varianza estimada del error.
se1 = sqrt(s1*diag(inv(Z'*Z)));    % Error estándar homocedástico.
se1_r = sqrt(diag(inv(Z'*Z)*(Z'*(diag(e_gorro.^2))*(N/(N-K))*Z)*inv(Z'*Z))); % Error estándar robusto.

% Test F (Utiliza errores estándares robustos). 

R = [0 1]';
c = [0 0]';                      % Valor de la hipotesis a testear -> H0 : a1 = 0.
q = 1;

ftest= (R'*zeta_gorro - c)' * inv(se1_r(2,1)*R'*inv(Z'*Z)*R) * (R'*zeta_gorro - c);  % Test F.
p_value1 = 2 * (1 - fcdf(abs(ftest), q, N - K)); 

% Resultados.

Primera_Etapa = table(zeta_gorro, se1_r, ...
    'VariableNames', {'Coeficiente', 'SE Robusto'});

Pregunta3 = table(beta_gorro, se, se_r, ...
    'VariableNames', {'Coeficiente', 'SE', 'SE Robusto'});


disp(['Para un alpha_1 = ', num2str(a1), ', la primera etapa tiene coeficientes y errores estándares:']);
disp(Primera_Etapa);

disp(['donde el Test F = ']);
disp(ftest);

disp(['y su segunda etapa será:']);
disp(Pregunta3);

end



%% Pregunta 4: Distribución asintótica de MC2E.

clear all   % Se hace clear all. De lo contrario los resultados se traslapan.

N = 1000;

b0 = 1;
b1 = 2;
b2 = 5;

a0 = -4;
a2 = 3; 

rng(1)               % Semilla.

for a1 = [0.1, 0.5, 1, 5, 10]

B = 1000;         % Número de simulaciones. 
bm = NaN(2,B);    % Vector de coeficientes simulados por Montecarlo.

for i = 1:B
    

e_i = randn(N,1);
u_i = randn(N,1);
W_i = normrnd(2, 1, N, 1);
v_i = rand(N, 1); 

Z_i = zeros(N,1); 
for i = 1:N
    if v_i(i) < 0.8                       
       Z_i(i) = 1;  
    else             
       Z_i(i) = 0;
    end
end

X_i = a0 + a1*Z_i + a2*W_i + u_i; 
Y = b0 + b1*X_i + b2*W_i + e_i;

% Primera etapa.
Z = [ones(N,1), Z_i];          % Omitimos W_i.
zeta_gorro = inv(Z'*Z)*Z'*X_i;  

% Segunda etapa.
X_hat = Z*zeta_gorro + u_gorro;
X = [ones(N,1), X_hat];         % Omitimos W_i.
beta_gorro = inv(X'*X)*X'*Y;
    
    m = randi(N,N,1);      % Vector de m pares aleatorios intependientes de tamaño n. 
    bm(:,i) = (X(m,:)'*X(m,:))\(X(m,:)'*Y(m)) ;
end
bm = sort(bm,2);

% Sesgo.
sesgo = mean(bm(2,:))- b1;
disp(['Para un alpha_1 = ', num2str(a1), ', el sesgo de nuestro estimador de MCO será:']);
    disp(sesgo);

% Calcular la densidad estimada
hold on;
[f,xi] = ksdensity(bm(2, :));
plot(xi,f,'LineWidth',2);
hold off;
end

xlabel('Valor');
ylabel('Densidad');
title('Curva de densidad estimada $\hat{\beta}_{1}$', 'Interpreter','latex');
legend('$\alpha_1 = 0.1$', '$\alpha_1 = 0.5$','$\alpha_1 = 1$', ...
    '$\alpha_1 = 5$', '$\alpha_1 = 10$','Interpreter','latex');
filename = ['densidad_alpha.png'];
    saveas(gcf, filename);





end


%% Datos para Stata.




clc;
clear;

rng(1);

for a1 = [0.1, 0.5, 1, 5, 10]

N = 1000;

b0 = 1;
b1 = 2;
b2 = 5;

a0 = -4;
a2 = 3; 

e_i = randn(N,1);
u_i = randn(N,1);
W_i = normrnd(2, 1, N, 1);
v_i = rand(N, 1); 

Z_i = zeros(N,1); 
for i = 1:N
    if v_i(i) < 0.8                       
       Z_i(i) = 1;  
    else             
       Z_i(i) = 0;
    end
end

X_i = a0 + a1*Z_i + a2*W_i + u_i; 
Y_i = b0 + b1*X_i + b2*W_i + e_i;

X = [ones(N,1), X_i];

beta_gorro = inv(X'*X)*X'*Y_i;

datos = [Y_i, X_i, Z_i, W_i];
filename = sprintf('datos_alpha_%.1f.csv', a1);
writematrix(datos, filename);

end

